# ğŸš€ EKS Fargate Cluster in Private Subnets (with EC2 Access)

This repository provisions a private ğŸ¯ Amazon EKS Cluster with Fargate profiles using CloudFormation, accessible only via an EC2 bastion host. Deployment is automated through Ansible and Jenkins CI/CD.

---

## ğŸ§° Technologies Used

- ğŸ—ï¸ **CloudFormation**: VPC, EKS Cluster, Fargate profile, EC2, IAM
- ğŸ¤– **Ansible**: Automation of stack deployment
- ğŸ” **Jenkins**: CI/CD pipeline
- ğŸ§  **kubectl + Helm**: Installed in EC2 for Kubernetes operations

---

## ğŸ§± Architecture

> âœ… GitHub â†’ Jenkins â†’ Ansible Agent â†’ AWS CloudFormation â†’ EKS Cluster Provisioning

![EKS Architecture](Arch-Diagram.drawio.png)

---

## ğŸ¯ Typical Use Case

You'd use this stack when you want:

âœ… A secure, private-only EKS cluster for production or dev  
âœ… Minimal operational overhead using Fargate (no node groups)  
âœ… An EC2 jumpbox (bastion host) to control and interact with your EKS cluster (no VPN required)  
âœ… A fully reproducible and infrastructure-as-code-based deployment pipeline

---

## ğŸ“ High-Level Purpose

This CloudFormation stack creates:

- ğŸŒ A custom VPC with public and private subnets across two AZs  
- â˜ï¸ An EKS Cluster running on Fargate (no EC2 workers)  
- ğŸ›¡ï¸ A bastion EC2 instance to interact with EKS via `kubectl`  
- ğŸ” IAM roles, security groups, and routing infrastructure  
- ğŸ“¤ Output values for automation: EKS cluster name, EC2 instance ID, and public IP

---

## ğŸ”© Main Components

### ğŸ”¹ 1. Networking Layer (VPC & Subnets)
- ğŸ§± **VPC**: DNS enabled
- ğŸŒ **Subnets**: 2 public + 2 private across AZs
- ğŸ”— **Internet/NAT Gateways** for egress
- ğŸ§­ **Route Tables** for subnet traffic routing

---

### ğŸ”¹ 2. Security & Access
- ğŸ” **Security Groups**
  - `InstanceSecurityGroup`: SSH access (port 22)
  - `EKSClusterAdditionalSecurityGroup`: Port 443 from EC2 to EKS control plane

- ğŸ‘¤ **IAM Roles**
  - `EC2AdminRole`: Admin access for EC2
  - `EKSClusterRole`: Cluster operations
  - `FargateProfileRole`: For pod execution

---

### ğŸ”¹ 3. EKS Cluster & Fargate Profile
- ğŸ§  **EKS Cluster**
  - ğŸ”’ Private endpoint only
  - ğŸ“ Logging: `api`, `audit`
  - ğŸ›¡ï¸ Linked to private subnets and SGs

- ğŸ¯ **Fargate Profile**
  - Schedules pods in: `default`, `kube-system`, `aws-observability`, etc.

---

### ğŸ”¹ 4. EKS Client EC2 Instance
- ğŸ’» **In public subnet** with internet access
- âš™ï¸ Installs:
  - `kubectl` ğŸ§ 
  - `helm` ğŸ“¦
- ğŸ” Uses `EC2AdminRole` to manage EKS cluster
- ğŸ”„ Can generate `kubeconfig` for private EKS cluster access

---

### ğŸ”¹ 5. Outputs
Upon successful stack creation, the following are printed:

âœ… **EKSClientInstanceId** â€” Bastion EC2 ID  
âœ… **EKSClientPublicIP** â€” Use to SSH into EC2  
âœ… **EKSClusterName** â€” For kubeconfig generation and scripting

---

## ğŸ› ï¸ Jenkins Pipeline

<img width="1300" height="738" alt="Jenkins Pipeline" src="https://github.com/user-attachments/assets/76c11dce-8896-4e81-ae74-08245f60e27f" />

### ğŸ“œ Jenkins Deployment Logs

<img width="1300" height="738" alt="Jenkins Logs" src="https://github.com/user-attachments/assets/6c1a2cba-1992-4865-9177-ad32de704ef6" />

---

## ğŸ“¡ AWS CNF Stack Status

<img width="1300" height="738" alt="Stack Status" src="https://github.com/user-attachments/assets/b73f0ecd-e6c3-4d9a-acf1-c20c2a349573" />

### ğŸ—ºï¸ VPC Resource Map

<img width="1300" height="738" alt="VPC Map" src="https://github.com/user-attachments/assets/e87a99f3-1907-42f8-8b6a-62b987927db8" />

---

## â˜¸ï¸ EKS Cluster View

<img width="1300" height="738" alt="EKS Cluster" src="https://github.com/user-attachments/assets/327c4b7d-0d28-4d5b-a3b5-5fee3aa33589" />

### ğŸ§‘â€ğŸ’» EKS Client Instance

<img width="1300" height="738" alt="EC2 Client" src="https://github.com/user-attachments/assets/d47b9cb7-05ff-48d5-bb83-c895d44e026b" />

### ğŸ” Access EKS Cluster from EC2

<img width="1300" height="738" alt="kubectl from EC2" src="https://github.com/user-attachments/assets/1cb1fdfd-6eeb-4028-92df-b089a61e8271" />

---

ğŸ“Œ *Feel free to fork, deploy, and customize for your AWS Kubernetes needs!*
